Brustein (2010)
===============

30 April
--------

### Summary

-   Political folks (scientists?) use something called sentiment
    analysis to gauge political opinion.
-   Sentiment analysis uses descriptors to gauge attitudes (sentiment)
    toward topic (words).
-   The folks have high hopes for this sort of analysis in predicting
    things like voting behavior.
-   There are still some issues.

### Challenges

-   Crimson Hexagon suffers from a huge selection bias problem in their
    analysis of the oil spill. Assigning blame is a primary cause for
    discussing disasters which do not affect you personally. When they
    do, while you may still assign blame, you have to discuss logistics.
-   The claim that sentiment analysis "can track which ideas develop
    organically" (para.9) is laughably overblown.
-   This does not solve the sampling bias problem. Landlines/cell phones
    have one sampling problem, sentiment analysis has another.
    Obviously, not everyone (or everyone of interest) is on Twitter (and
    they do focus on Twitter for this piece). It is not as useful as
    these folks want to make it sound.
-   This piece (and the people they interviewed) misunderstand social
    interactions on Twitter relatively fundamentally. They talk about "a
    message . . . that had been resent many times" (para. 13), which,
    apart from being the worst description I've ever read of retweeting,
    fails to capture that the speech act in question is *endorsing*, not
    *retelling*.
-   The metadata problem is worth much more than a sentence.
-   Sentiment analysis can't track "what themes gain traction" (para.
    15). It can track only the valence of the traction.

### Questions

-   Why didn't they interview more *real* sentiment analysis people?
    Linguamatics is not sentiment analysis. They're text mining. That is
    not the same thing.
